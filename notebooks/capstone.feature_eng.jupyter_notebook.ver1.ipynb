{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Feature Engineering Notebook", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Imports", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import types\nimport re\n\nfrom botocore.client import Config\nimport ibm_boto3\nimport numpy as np\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder, StandardScaler\nimport pandas as pd\nimport pickle\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline"
        }, 
        {
            "source": "### Loading data from object storage", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def download_file_cos(credentials, local_file_name, key):  \n    cos = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id=credentials['IBM_API_KEY_ID'],\n    ibm_service_instance_id=credentials['IAM_SERVICE_ID'],\n    ibm_auth_endpoint=credentials['IBM_AUTH_ENDPOINT'],\n    config=Config(signature_version='oauth'),\n    endpoint_url=credentials['ENDPOINT'])\n    try:\n        res=cos.download_file(Bucket=credentials['BUCKET'], Key=key, Filename=local_file_name)\n    except Exception as e:\n        print(Exception, e)\n    else:\n        print('File Downloaded')"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "File Downloaded\nFile Downloaded\n"
                }
            ], 
            "source": "download_file_cos(credentials=credentials, local_file_name='df_raw_pickle.pickle', key='df_raw_pickle.pickle')\ndownload_file_cos(credentials=credentials, local_file_name='dtypes_dict.pickle', key='dtypes_dict.pickle')"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df = pd.read_pickle('df_raw_pickle.pickle')\n\nwith open('dtypes_dict.pickle', 'rb') as pkl:\n    dtypes_dict = pickle.load(pkl)"
        }, 
        {
            "source": "### NA values\nFill N/A values with `-1`", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df.season_holidayed_code.fillna(-1, inplace = True)\ndf.state_code_residence.fillna(-1, inplace = True)"
        }, 
        {
            "source": "### Correct the data types", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Convert categorical features to `category` data type", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "for col in dtypes_dict['category_feats']:\n    df.loc[:, col] = df.loc[:, col].astype('category')"
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "reservation_id                              category\nreservationstatusid_code                    category\ncluster_code                                category\nmemberid                                    category\nbooking_type_code                           category\nmember_age_buckets                          category\nstate_code_resort                           category\nresort_id                                   category\nresort_type_code                            category\nroom_type_booked_code                       category\npersontravellingid                          category\nmain_product_code                           category\nchannel_code                                category\nresort_region_code                          category\ncheckout_date                         datetime64[ns]\ncheckin_date                          datetime64[ns]\nbooking_date                          datetime64[ns]\nseason_holidayed_code                        float64\nstate_code_residence                         float64\namount_spent_per_room_night_scaled           float64\nnumberofchildren                               int64\nroomnights                                     int64\nnumberofadults                                 int64\ntotal_pax                                      int64\ndtype: object\n"
                }
            ], 
            "source": "# Check the data types of the featuers\nprint(df.dtypes.astype('str').sort_values())"
        }, 
        {
            "source": "Add numerical features list to data types dictionary", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "dtypes_dict['num_feats'] = [x for x in df.columns if x not in dtypes_dict['date_feats']+dtypes_dict['category_feats']]"
        }, 
        {
            "source": "### Feature Engineering\n#### Date Features", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df['booking_in_advance'] = (df['checkin_date'] - df['booking_date']).dt.days\ndf['days_stayed'] = (df['checkout_date'] - df['checkin_date']).dt.days"
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# function taken from https://github.com/fastai/fastai/blob/master/old/fastai/structured.py\ndef add_datepart(df, fldname, drop=True, time=False, errors=\"raise\"):\t\n    \"\"\"add_datepart converts a column of df from a datetime64 to many columns containing\n    the information from the date. This applies changes inplace.\n    Parameters:\n    -----------\n    df: A pandas data frame. df gain several new columns.\n    fldname: A string that is the name of the date column you wish to expand.\n        If it is not a datetime64 series, it will be converted to one with pd.to_datetime.\n    drop: If true then the original date column will be removed.\n    time: If true time features: Hour, Minute, Second will be added.\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({ 'A' : pd.to_datetime(['3/11/2000', '3/12/2000', '3/13/2000'], infer_datetime_format=False) })\n    >>> df\n        A\n    0   2000-03-11\n    1   2000-03-12\n    2   2000-03-13\n    >>> add_datepart(df, 'A')\n    >>> df\n        AYear AMonth AWeek ADay ADayofweek ADayofyear AIs_month_end AIs_month_start AIs_quarter_end AIs_quarter_start AIs_year_end AIs_year_start AElapsed\n    0   2000  3      10    11   5          71         False         False           False           False             False        False          952732800\n    1   2000  3      10    12   6          72         False         False           False           False             False        False          952819200\n    2   2000  3      11    13   0          73         False         False           False           False             False        False          952905600\n    \"\"\"\n    fld = df[fldname]\n    fld_dtype = fld.dtype\n    if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n        fld_dtype = np.datetime64\n\n    if not np.issubdtype(fld_dtype, np.datetime64):\n        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True, errors=errors)\n    targ_pre = re.sub('[Dd]ate$', '', fldname)\n    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n    if time: attr = attr + ['Hour', 'Minute', 'Second']\n    for n in attr: df[targ_pre + n] = getattr(fld.dt, n.lower())\n    df[targ_pre + 'Elapsed'] = fld.astype(np.int64) // 10 ** 9\n    if drop: df.drop(fldname, axis=1, inplace=True)"
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Apply add_datepart function to datetime features\nfor col in dtypes_dict['date_feats']:\n    add_datepart(df, col, drop=True)"
        }, 
        {
            "source": "#### Other Features", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df['n_people'] = df['numberofadults'] + df['numberofchildren']"
        }, 
        {
            "source": "Revisit the data types", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "bin_feats = []\n\nfor col in df.columns:\n    if len(df[col].unique()) == 2:\n        bin_feats.append(col)\n\ndtypes_dict['bin_feats'] = bin_feats"
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "known_feats = sum(dtypes_dict.values(), [])"
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "dtypes_dict['num_feats'] += [c for c in df.columns if c not in known_feats]"
        }, 
        {
            "source": "### Preprocessing", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Converting binary-type columns values to [0, 1]", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 17, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "lb = LabelBinarizer()\n\nfor col in dtypes_dict['bin_feats']:\n    df[col] = lb.fit_transform(df[col])"
        }, 
        {
            "source": "Label Encoding the categorical features", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 18, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "le = LabelEncoder()\n\nfor col in dtypes_dict['category_feats']:\n    df[col] = le.fit_transform(df[col])"
        }, 
        {
            "source": "Scaling the numerical features", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 19, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "ss = StandardScaler()\n\nfor col in dtypes_dict['num_feats']:\n    df[col] = ss.fit_transform(df[col].values.reshape(-1, 1))"
        }, 
        {
            "source": "### Data export", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 24, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df.to_csv('df_processed.csv', header=True, index=False)\n\nwith open('df_processed_pickle.pickle', 'wb') as pkl:\n    pickle.dump(df, pkl, protocol=pickle.HIGHEST_PROTOCOL)"
        }, 
        {
            "execution_count": 21, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "cos.upload_file(Filename='df_processed_pickle.pickle', Bucket=credentials['BUCKET'], Key='df_processed_pickle.pickle')\ncos.upload_file(Filename='df_processed.csv', Bucket=credentials['BUCKET'], Key='df_processed.csv')"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}